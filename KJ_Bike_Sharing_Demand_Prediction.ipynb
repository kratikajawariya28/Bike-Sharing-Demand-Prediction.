{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "iky9q4vBYrdO",
        "QHF8YVU7Yuh3",
        "bbFf2-_FphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kratikajawariya28/Bike-Sharing-Demand-Prediction./blob/main/KJ_Bike_Sharing_Demand_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -**  Dharmendra Yadav\n",
        "##### **Team Member 2 -**  Pranita Tiwari\n",
        "##### **Team Member 3 -**  Kratika Jawariya\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proliferation of bike and scooter ride-sharing companies in urban settings has introduced a pressing challenge: the accurate prediction of demand for their services. The consequences of overestimating or underestimating this demand can be substantial, leading to either resource wastage or revenue loss, respectively. To address this intricate issue, a project has been initiated with the primary objective of amalgamating historical bike usage patterns with weather data to formulate forecasts for bike rental demand.\n",
        "\n",
        "\n",
        "This endeavor draws upon a dataset encompassing eight key input variables: 'Date,' 'Seasons,' 'Holiday,' 'Functional day,' 'Temperature,' 'Humidity,' 'Dew Point Temperature,' and 'Windspeed.' Employing an array of Python libraries, including Pandas, Seaborn, NumPy, and scikit-learn (sklearn), the project endeavors to construct a predictive algorithm. Through rigorous assessment and comparison of various models, the ultimate goal is to identify algorithms capable of generating precise predictions that can be pragmatically deployed in real-world scenarios.\n",
        "\n",
        "\n",
        "The significance of accurate bike rental demand forecasting cannot be overstated. For ride-sharing companies, this entails the potential to fine-tune their resource allocation, minimizing waste and maximizing profitability. By optimizing bike maintenance schedules, parking space allotments, and operational planning based on projected demand, these companies can substantially enhance their operational efficiency.\n",
        "\n",
        "\n",
        "Moreover, the ramifications of precise demand predictions extend to customer satisfaction and overall user experience. By guaranteeing an adequate supply of bikes and scooters that aligns seamlessly with expected demand, customers are far less likely to grapple with issues related to availability. This, in turn, fosters greater customer loyalty, triggers positive word-of-mouth recommendations, and propels sustained business growth.\n",
        "\n",
        "\n",
        "Beyond these immediate benefits, it's essential to recognize that bike and scooter ride-sharing services are heralded as environmentally friendly alternatives to traditional modes of transportation. By integrating weather data into the demand forecasting process, it becomes feasible to synchronize the availability of bikes and scooters with weather conditions that are conducive to cycling. This strategic alignment encourages more individuals to opt for biking as their preferred mode of transportation, consequently reducing traffic congestion and mitigating carbon emissions. Accurate demand forecasting thus aligns with the broader objective of promoting sustainable and eco-friendly urban mobility.\n",
        "\n",
        "\n",
        "In summation, the project's overarching objective to fuse historical bike usage patterns with weather data for precise demand forecasting holds immense potential for the bike and scooter ride-sharing industry. By harnessing advanced algorithms and machine learning techniques, the project strives to optimize resource allocation, curtail wastage, and elevate profitability for ride-sharing companies. Concurrently, it aims to elevate customer satisfaction, champion eco-friendly transportation options, and alleviate the scourge of traffic congestion and carbon emissions. Data-driven insights wield the potential to exert a positive influence on both the business and environmental facets of the bike and scooter ride-sharing industry, culminating in a more sustainable and efficient urban mobility landscape.\n",
        "\n",
        "\n",
        "As we delve deeper into the multifaceted implications of this project, it becomes apparent that the convergence of historical bike usage data and meteorological insights represents a paradigm shift in urban transportation dynamics. The proliferation of bike and scooter ride-sharing services has undoubtedly revolutionized the way people navigate cities, offering convenient, eco-friendly, and cost-effective alternatives to traditional modes of transport.\n",
        "\n",
        "\n",
        "Yet, with innovation comes the imperative to address challenges and optimize operations. One of the foremost challenges faced by ride-sharing companies operating in urban environments is the accurate prediction of demand for their services. The consequences of getting this prediction wrong can be significant. Overestimating demand leads to unnecessary resource allocation, resulting in excess bikes and scooters that remain underutilized. Conversely, underestimating demand can leave customers frustrated when they can't find available vehicles, potentially causing them to seek alternative transportation options.\n",
        "\n",
        "\n",
        "This challenge of demand prediction in the bike and scooter ride-sharing industry is where the aforementioned project comes into play. By combining historical usage patterns with meteorological data, the project aims to develop a robust forecasting model that can provide accurate estimates of future demand. The dataset used in this endeavor includes eight critical input variables, ranging from date and seasonal factors to weather-related metrics like temperature, humidity, dew point temperature, and wind speed.\n",
        "\n",
        "\n",
        "To construct the predictive algorithm, the project harnesses the power of several Python libraries, including Pandas for data manipulation, Seaborn for data visualization, NumPy for numerical computations, and scikit-learn (sklearn) for machine learning model development. Through a meticulous process of model evaluation and selection, the project seeks to identify algorithms that not only yield accurate predictions but are also practical for real-world deployment.\n",
        "\n",
        "\n",
        "The implications of successful demand forecasting in this context are profound. For ride-sharing companies, it means the ability to fine-tune their operations with surgical precision. They can optimize the allocation of bikes and scooters, ensuring that resources are neither wasted nor insufficient to meet demand. This not only leads to cost savings but also directly impacts profitability by minimizing unnecessary expenses.\n",
        "\n",
        "\n",
        "Furthermore, the benefits extend to customer experience. In an era where convenience is paramount, ensuring that bikes and scooters are readily available when customers need them is a critical factor in building loyalty. Accurate demand forecasts help in achieving this goal, resulting in satisfied users who are more likely to continue using the service and recommend it to others.\n",
        "\n",
        "\n",
        "Beyond business considerations, there's a notable environmental aspect to this project. Bike and scooter ride-sharing services are often celebrated for their eco-friendliness, providing a sustainable alternative to gasoline-powered vehicles. By factoring in weather data, the project aims to align the availability of bikes and scooters with weather conditions conducive to cycling. This not only encourages more people to choose biking as a transportation mode but also contributes to reduced traffic congestion and lower carbon emissions, two pressing issues in urban areas worldwide.\n",
        "\n",
        "\n",
        "\n",
        "In essence, the project represents a convergence of technology, data science, and urban planning. It seeks to harness the power of data-driven insights to reshape the landscape of urban mobility. By optimizing resource allocation, reducing waste, enhancing customer satisfaction, and promoting sustainable transportation, it embodies the ideals of a smart, efficient, and eco-conscious city. As the project unfolds and its insights are put into practice, it has the potential to create a ripple effect, influencing not only the bike and scooter ride-sharing industry but also the broader urban transportation ecosystem.\n",
        "\n",
        "\n",
        "In conclusion, the project's mission to fuse historical bike usage patterns with weather data for precise demand forecasting is poised to have a transformative impact. It aligns with the evolving ethos of urban mobility, where data-driven decisions hold the key to efficiency, sustainability, and customer satisfaction. The synergy of technology and environmental consciousness shines a light on a path toward a more sustainable and efficient urban mobility landscape. Through this project, we witness the power of innovation in shaping the cities of tomorrow."
      ],
      "metadata": {
        "id": "UmgQHvrq_4J7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import all the required python libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting the google drive with the google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read  file\n",
        "\n",
        "df = pd.read_excel('/content/SeoulBikeData.xlsx')"
      ],
      "metadata": {
        "id": "BFhvS9JTiLAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "IegCG1sGtMAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "df.info()  ## we will check if there is nulll value"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " There is no duplicate entry in the data"
      ],
      "metadata": {
        "id": "068TITHJIGZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.heatmap(df.isnull(), cbar=True, yticklabels=False)\n",
        "plt.xlabel(\"Column_Name\", size=14, weight=\"bold\")\n",
        "plt.title(\" missing values in column\",fontweight=\"bold\",size=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output suggests that our DataFrame is entirely populated, with no missing values present in any of its columns. This is a positive finding in data analysis since missing data often necessitates extra steps, such as data imputation or handling, but in this scenario,  dataset appears to be free from any missing values, indicating data cleanliness."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include = \"all\").T"
      ],
      "metadata": {
        "id": "RqpeEqKLvDH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Date:**   This variable represents the date and time of the recorded data. It contains 8760 observations, spanning 365 unique dates. The most frequently occurring date is \"2017-01-12 00:00:00,\" which appears 24 times.\n",
        "\n",
        "\n",
        "**Rented Bike Count:**  This variable represents the number of rented bikes at a given time. It is a numerical variable with a mean (average) of approximately 704.60 bikes and a standard deviation of approximately 644.99 bikes. The minimum number of rented bikes recorded is 0, and the maximum is 3556. The data ranges from 0 to 3556 bikes, with quartiles at 191, 504.5, and 1065.25 bikes.\n",
        "\n",
        "\n",
        "**Hour:**  This variable represents the hour of the day when the data was recorded. It is a numerical variable with a mean of 11.5 hours and a standard deviation of approximately 6.92 hours. The data spans from 0 to 23 hours, with quartiles at 5.75, 11.5, and 17.25 hours.\n",
        "\n",
        "\n",
        "**Temperature():** This variable represents the temperature in degrees Celsius. It is a numerical variable with a mean of approximately 12.88°C and a standard deviation of approximately 11.94°C. The recorded temperatures range from -17.8°C to 39.4°C, with quartiles at 3.5°C, 13.7°C, and 22.5°C.\n",
        "\n",
        "**Humidity(%):** This variable represents the relative humidity percentage. It is a numerical variable with a mean of approximately 58.23% and a standard deviation of approximately 20.36%. The humidity values range from 0% to 98%, with quartiles at 42%, 57%, and 74%.\n",
        "\n",
        "\n",
        "**Wind speed (m/s):**  This variable represents the wind speed in meters per second. It is a numerical variable with a mean of approximately 1.72 m/s and a standard deviation of approximately 1.04 m/s. Wind speeds range from 0 m/s to 7.4 m/s, with quartiles at 0.9 m/s, 1.5 m/s, and 2.3 m/s.\n",
        "\n",
        "\n",
        "**Visibility (10m):**  This variable represents visibility in meters. It is a numerical variable with a mean of approximately 1436.83 meters and a standard deviation of approximately 608.30 meters. Visibility values range from 27 meters to 2000 meters, with quartiles at 940 meters, 1698 meters, and 2000 meters.\n",
        "\n",
        "\n",
        "**Dew point temperature():** This variable represents the dew point temperature in degrees Celsius. It is a numerical variable with a mean of approximately 4.07°C and a standard deviation of approximately 13.06°C. Dew point temperatures range from -30.6°C to 27.2°C, with quartiles at -4.7°C, 5.1°C, and 14.8°C.\n",
        "\n",
        "\n",
        "**Solar Radiation (MJ/m2):**  This variable represents solar radiation in megajoules per square meter. It is a numerical variable with a mean of approximately 0.57 MJ/m2 and a standard deviation of approximately 0.87 MJ/m2. Solar radiation values range from 0 MJ/m2 to 3.52 MJ/m2.\n",
        "\n",
        "\n",
        "**Rainfall(mm):**  This variable represents rainfall in millimeters. It is a numerical variable with a mean of approximately 0.15 mm and a standard deviation of approximately 1.13 mm. Rainfall values range from 0 mm to 35 mm.\n",
        "\n",
        "\n",
        "**Snowfall (cm):**  This variable represents snowfall in centimeters. It is a numerical variable with a mean of approximately 0.08 cm and a standard deviation of approximately 0.44 cm. Snowfall values range from 0 cm to 8.8 cm.\n",
        "\n",
        "\n",
        "**Seasons:** This categorical variable represents the season during which the data was recorded. It has 4 unique categories: \"Spring,\" \"Summer,\" \"Autumn,\" and \"Winter.\" The most frequently occurring season is \"Spring,\" which appears 2208 times.\n",
        "\n",
        "\n",
        "**Holiday:**  This categorical variable indicates whether it was a holiday or not during the recorded data. It has 2 unique categories: \"No Holiday\" and \"Holiday.\" The most frequently occurring category is \"No Holiday,\" which appears 8328 times.\n",
        "\n",
        "\n",
        "**Functioning Day:** This categorical variable indicates whether the day was a functioning day (e.g., a regular working day) or not. It has 2 unique categories: \"Yes\" and \"No.\" The most frequently occurring category is \"Yes,\" which appears 8465 times.\n",
        "\n",
        "\n",
        "These variable descriptions provide a clear understanding of the nature, range, and distribution of each variable in our dataset, which can be helpful for data analysis and modeling."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in df.columns:\n",
        "  print(i, ':',df[i].unique(), \"\\n\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "sQ7tdvw4E-vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])  # converting date column dtype object to datetime\n",
        "df[\"weekday\"] = df[\"Date\"].dt.day_name() # we are going to create one more column to know what day it is\n",
        "df[\"Day\"] = df[\"Date\"].dt.day  # now we are going to spilt the date in day, month, year\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "\n",
        "# now we will remove the date\n",
        "\n",
        "df.drop(\"Date\", axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8RnTLJK4GBa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have  total 17 coloumns"
      ],
      "metadata": {
        "id": "2KzTfMKRNmlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "EhiwAAaqGBs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for duplicates and missing values, and provides variable descriptions. we also performs data wrangling by converting date columns, extracting date components, and dropping the original date column"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    }
  ]
}